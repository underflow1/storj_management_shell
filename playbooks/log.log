./folding.sh: line 30: ansible-playbook: command not found
./folding.sh: line 30: ansible-playbook: command not found
./folding.sh: line 30: ansible-playbook: command not found
./folding.sh: line 30: ansible-playbook: command not found
./folding.sh: line 31: ansible-playbook: command not found
./folding.sh: line 58: ansible-playbook: command not found
./folding.sh: line 59: ansible-playbook: command not found
./folding.sh: line 60: ansible-playbook: command not found
./folding.sh: line 58: ansible-playbook: command not found

PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
fatal: [localhost]: FAILED! => {"msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', defaults_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '../configs/defaults'. file not found, use -vvvvv to see paths searched"}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
fatal: [localhost]: FAILED! => {"msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', defaults_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '../configs/defaults'. file not found, use -vvvvv to see paths searched"}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
fatal: [localhost]: FAILED! => {"msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', defaults_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '../defaults'. file not found, use -vvvvv to see paths searched"}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
fatal: [localhost]: FAILED! => {"msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', defaults_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '../../defaults'. file not found, use -vvvvv to see paths searched"}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
redirecting (type: modules) community.network.routeros_command to community.routeros.command
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: node_create_full.yml *************************************************
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
fatal: [localhost]: FAILED! => {"msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', defaults_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '../../defaults'. file not found, use -vvvvv to see paths searched"}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
redirecting (type: modules) community.network.routeros_command to community.routeros.command
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Skipping callback 'default', as we already have a stdout callback.
Skipping callback 'minimal', as we already have a stdout callback.
Skipping callback 'oneline', as we already have a stdout callback.

PLAYBOOK: node_create_full.yml *************************************************
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
fatal: [localhost]: FAILED! => {
    "msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', defaults_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '../../defaults'. file not found, use -vvvvv to see paths searched"
}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
looking for "../../defaults" at "/root/storj_management_shell_dev/playbooks/files/../../defaults"
looking for "../../defaults" at "/root/storj_management_shell_dev/playbooks/../../defaults"
looking for "../../defaults" at "/root/storj_management_shell_dev/playbooks/files/../../defaults"
looking for "../../defaults" at "/root/storj_management_shell_dev/playbooks/../../defaults"
File lookup using None as file
fatal: [localhost]: FAILED! => {
    "msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', defaults_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '../../defaults'. file not found, use -vvvvv to see paths searched"
}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  did not find expected key

The error appears to be in '/root/.config/sms/inventory/group_vars/all.yml': line 3, column 39, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

nodeconfig_filename: "../configuration_items/node/{{ NODE_ID }}/config"
defaults_filename: {{ inventory_dir }}/defaults
                                      ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  did not find expected key

The error appears to be in '/root/.config/sms/inventory/group_vars/all.yml': line 3, column 39, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

nodeconfig_filename: "../configuration_items/node/{{ NODE_ID }}/config"
defaults_filename: {{ inventory_dir }}/defaults
                                      ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
looking for "../configuration_items/node/384/config" at "/root/storj_management_shell_dev/playbooks/files/../configuration_items/node/384/config"
looking for "../configuration_items/node/384/config" at "/root/storj_management_shell_dev/playbooks/../configuration_items/node/384/config"
looking for "../configuration_items/node/384/config" at "/root/storj_management_shell_dev/playbooks/files/../configuration_items/node/384/config"
looking for "../configuration_items/node/384/config" at "/root/storj_management_shell_dev/playbooks/../configuration_items/node/384/config"
File lookup using None as file
fatal: [localhost]: FAILED! => {
    "msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', nodeconfig_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '../configuration_items/node/384/config'. file not found, use -vvvvv to see paths searched"
}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
fatal: [localhost]: FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/node_create_full.yml': line 7, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  pre_tasks:\n    - add_host:\n      ^ here\n"
}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
fatal: [localhost]: FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: 'CONFIG' is undefined. 'CONFIG' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/node_create_full.yml': line 7, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  pre_tasks:\n    - add_host:\n      ^ here\n"
}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
fatal: [localhost]: FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: 'CONFIG' is undefined. 'CONFIG' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/node_create_full.yml': line 7, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  pre_tasks:\n    - add_host:\n      ^ here\n"
}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
fatal: [localhost]: FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: 'CONFIG' is undefined. 'CONFIG' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/node_create_full.yml': line 7, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  pre_tasks:\n    - add_host:\n      ^ here\n"
}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  did not find expected key

The error appears to be in '/root/.config/sms/inventory/group_vars/all.yml': line 8, column 41, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

VPNCONFIG: "{{ lookup('file', vpnconfig_filename) | from_json }}"
hostconfig_filename: {{ inventory_dir }}/../configuration_items/host/{{NODECONFIG.NODE_HOST_ID}}/config
                                        ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  did not find expected key

The error appears to be in '/root/.config/sms/inventory/group_vars/all.yml': line 10, column 45, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

HOSTCONFIG: "{{ lookup('file', hostconfig_filename) | from_json }}"
mikrotikconfig_filename: {{ inventory_dir }}/../configuration_items/mikrotik/{{NODECONFIG.NODE_MIKROTIK_ID}}/config
                                            ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
fatal: [localhost]: FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: 'CONFIG' is undefined. 'CONFIG' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/node_create_full.yml': line 7, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  pre_tasks:\n    - add_host:\n      ^ here\n"
}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
fatal: [localhost]: FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined. {{ inventory_dir }}/defaults: 'inventory_dir' is undefined. 'inventory_dir' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/node_create_full.yml': line 7, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  pre_tasks:\n    - add_host:\n      ^ here\n"
}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  could not find expected ':'

The error appears to be in '/root/.config/sms/inventory/group_vars/all.yml': line 4, column 1, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

print(nodeconfig_filename)
defaults_filename: "{{ inventory_dir }}/defaults"
^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384, CONFIG_PATH=/root/.config/sms',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384, : select hosts] *************************************************
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  could not find expected ':'

The error appears to be in '/root/.config/sms/inventory/group_vars/all.yml': line 4, column 1, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

print(nodeconfig_filename)
defaults_filename: "{{ inventory_dir }}/defaults"
^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384, CONFIG_PATH=/root/.config/sms',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384, : select hosts] *************************************************

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
File lookup using /root/.config/sms/defaults as file
File lookup using None as file
fatal: [localhost]: FAILED! => {
    "msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', nodeconfig_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '/root/.config/sms/configuration_items/node/384,/config'. file not found, use -vvvvv to see paths searched"
}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384, CONFIG_PATH=/root/.config/sms',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384, : select hosts] *************************************************

TASK [debug] *******************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
File lookup using /root/.config/sms/defaults as file
File lookup using None as file
fatal: [localhost]: FAILED! => {
    "msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', nodeconfig_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '/root/.config/sms/configuration_items/node/384,/config'. file not found, use -vvvvv to see paths searched"
}

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384;CONFIG_PATH=/root/.config/sms',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384;CONFIG_PATH=/root/.config/sms : select hosts] ********************

TASK [debug] *******************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
fatal: [localhost]: FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/node_create_full.yml': line 7, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  pre_tasks:\n    - debug:\n      ^ here\n"
}

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384;CONFIG_PATH=/root/.config/sms',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384;CONFIG_PATH=/root/.config/sms : select hosts] ********************

TASK [debug] *******************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
fatal: [localhost]: FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: {{ DEFAULTS | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ DEFAULTS | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/node_create_full.yml': line 7, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  pre_tasks:\n    - debug:\n      ^ here\n"
}

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384 CONFIG_PATH=/root/.config/sms',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using None as file
fatal: [localhost]: FAILED! => {
    "msg": "An unhandled exception occurred while templating '{{ DEFAULTS | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ { 'NODE_PORT_EXTERNAL': NODECONFIG.NODE_PORT_EXTERNAL | default(DEFAULTS.NODE_PORT_EXTERNAL_PREFIX  + NODE_ID), 'NODE_PORT_CONSOLE': NODECONFIG.NODE_PORT_CONSOLE | default(DEFAULTS.NODE_PORT_CONSOLE_PREFIX + NODE_ID), 'NODE_IP_ADDRESS_EXTERNAL': NODECONFIG.NODE_IP_ADDRESS_EXTERNAL | default(VPNCONFIG.VPN_IP_ADDRESS_LIST[TEMPCONFIG01.NODE_VPN_IP_ADDRESS_NUMBER]), 'NODE_IP_ADDRESS_INTERNAL': NODECONFIG.NODE_IP_ADDRESS_INTERNAL | default('10.' + NODECONFIG.NODE_HOST_ID|string + '.0.254' ), 'MIKROTIK_IP_ADDRESS_INTERNAL': MIKROTIKCONFIG.MIKROTIK_IP_ADDRESS_INTERNAL | default('10.' + NODECONFIG.NODE_MIKROTIK_ID|string + '.0.1') } }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', vpnconfig_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '/root/.config/sms/configuration_items/configuration_items/vpn/226/config'. file not found, use -vvvvv to see paths searched"
}

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384 CONFIG_PATH=/root/.config/sms',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
ok: [localhost] => {
    "msg": {
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 500,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:9
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
fatal: [localhost]: FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'NODE_HOST_ID'. 'dict object' has no attribute 'NODE_HOST_ID'\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/node_create_full.yml': line 9, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n        msg: \"{{ CONFIG }}\"\n    - add_host:\n      ^ here\n"
}

NO MORE HOSTS LEFT *************************************************************

PLAY RECAP *********************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

ansible-playbook [core 2.16.3]
  config file = /root/.ansible.cfg
  configured module search path = ['/root/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules']
  ansible python module location = /root/venv/lib/python3.11/site-packages/ansible
  ansible collection location = /root/.ansible/collections:/usr/share/ansible/collections
  executable location = /root/venv/bin/ansible-playbook
  python version = 3.11.2 (main, Mar 13 2023, 12:18:29) [GCC 12.2.0] (/root/venv/bin/python3)
  jinja version = 3.1.3
  libyaml = True
Using /root/.ansible.cfg as config file
setting up inventory plugins
Loading collection ansible.builtin from 
host_list declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
script declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
auto declined parsing /root/.config/sms/inventory/static-inventory as it did not pass its verify_file() method
Parsed /root/.config/sms/inventory/static-inventory inventory source with ini plugin
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading collection community.docker from /root/venv/lib/python3.11/site-packages/ansible_collections/community/docker
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
redirecting (type: modules) ansible.builtin.docker_container_info to community.docker.docker_container_info
Loading collection community.network from /root/venv/lib/python3.11/site-packages/ansible_collections/community/network
redirecting (type: modules) community.network.routeros_command to community.routeros.command
Loading collection community.routeros from /root/venv/lib/python3.11/site-packages/ansible_collections/community/routeros
redirecting (type: modules) ansible.builtin.docker_container to community.docker.docker_container
Loading callback plugin default of type stdout, v2.0 from /root/venv/lib/python3.11/site-packages/ansible/plugins/callback/default.py
Attempting to use 'default' callback.
Skipping callback 'default', as we already have a stdout callback.
Attempting to use 'junit' callback.
Attempting to use 'minimal' callback.
Skipping callback 'minimal', as we already have a stdout callback.
Attempting to use 'oneline' callback.
Skipping callback 'oneline', as we already have a stdout callback.
Attempting to use 'tree' callback.

PLAYBOOK: node_create_full.yml *************************************************
Positional arguments: playbooks/node_create_full.yml
verbosity: 5
connection: ssh
become_method: sudo
tags: ('all',)
inventory: ('/root/.config/sms/inventory',)
extra_vars: ('NODE_ID=384 CONFIG_PATH=/root/.config/sms',)
forks: 5
5 plays in playbooks/node_create_full.yml

PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:7
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:9
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
creating host via 'add_host': hostname=host43
changed: [localhost] => {
    "add_host": {
        "groups": [
            "current_host"
        ],
        "host_name": "host43",
        "host_vars": {
            "group": "current_host"
        }
    },
    "changed": true
}

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:12
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
creating host via 'add_host': hostname=mikrotik43
changed: [localhost] => {
    "add_host": {
        "groups": [
            "current_mikrotik"
        ],
        "host_name": "mikrotik43",
        "host_vars": {
            "group": "current_mikrotik"
        }
    },
    "changed": true
}

TASK [add_host] ****************************************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:15
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
creating host via 'add_host': hostname=vpn226
changed: [localhost] => {
    "add_host": {
        "groups": [
            "current_vpn"
        ],
        "host_name": "vpn226",
        "host_vars": {
            "group": "current_vpn"
        }
    },
    "changed": true
}

PLAY [node384 : create node docker container from scratch] *********************
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file

TASK [node384 : get dataset mount point] ***************************************
task path: /root/storj_management_shell_dev/playbooks/node_create_full.yml:23
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/defaults as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/vpn/226/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/host/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
File lookup using /root/.config/sms/configuration_items/node/384/config as file
File lookup using /root/.config/sms/configuration_items/mikrotik/43/config as file
<85.192.20.98> ESTABLISH SSH CONNECTION FOR USER: None
<85.192.20.98> SSH: ansible.cfg set ssh_args: (-C)(-o)(ControlMaster=auto)(-o)(ControlPersist=60s)
<85.192.20.98> SSH: ANSIBLE_HOST_KEY_CHECKING/host_key_checking disabled: (-o)(StrictHostKeyChecking=no)
<85.192.20.98> SSH: ANSIBLE_PRIVATE_KEY_FILE/private_key_file/ansible_ssh_private_key_file set: (-o)(IdentityFile="./keys/id_rsa_old")
<85.192.20.98> SSH: ansible_password/ansible_ssh_password not set: (-o)(KbdInteractiveAuthentication=no)(-o)(PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey)(-o)(PasswordAuthentication=no)
<85.192.20.98> SSH: ANSIBLE_TIMEOUT/timeout set: (-o)(ConnectTimeout=10)
<85.192.20.98> SSH: Set ssh_common_args: ()
<85.192.20.98> SSH: Set ssh_extra_args: ()
<85.192.20.98> SSH: found only ControlPersist; added ControlPath: (-o)(ControlPath="/root/.ansible/cp/d17929321e")
<85.192.20.98> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking=no -o 'IdentityFile="./keys/id_rsa_old"' -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o ConnectTimeout=10 -o 'ControlPath="/root/.ansible/cp/d17929321e"' 85.192.20.98 '/bin/sh -c '"'"'echo ~ && sleep 0'"'"''
<85.192.20.98> (255, b'', b'OpenSSH_9.2p1 Debian-2+deb12u2, OpenSSL 3.0.11 19 Sep 2023\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 85.192.20.98 is address\r\ndebug3: expanded UserKnownHostsFile \'~/.ssh/known_hosts\' -> \'/root/.ssh/known_hosts\'\r\ndebug3: expanded UserKnownHostsFile \'~/.ssh/known_hosts2\' -> \'/root/.ssh/known_hosts2\'\r\ndebug1: auto-mux: Trying existing master\r\ndebug1: Control socket "/root/.ansible/cp/d17929321e" does not exist\r\ndebug3: ssh_connect_direct: entering\r\ndebug1: Connecting to 85.192.20.98 [85.192.20.98] port 22.\r\ndebug3: set_sock_tos: set socket 3 IP_TOS 0x10\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: fd 3 clearing O_NONBLOCK\r\ndebug1: Connection established.\r\ndebug3: timeout: 10000 ms remain after connect\r\ndebug1: identity file ./keys/id_rsa_old type -1\r\ndebug1: identity file ./keys/id_rsa_old-cert type -1\r\ndebug1: Local version string SSH-2.0-OpenSSH_9.2p1 Debian-2+deb12u2\r\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_8.4p1 Debian-5+deb11u1\r\ndebug1: compat_banner: match: OpenSSH_8.4p1 Debian-5+deb11u1 pat OpenSSH* compat 0x04000000\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: Authenticating to 85.192.20.98:22 as \'root\'\r\ndebug3: record_hostkey: found key type ED25519 in file /root/.ssh/known_hosts:1\r\ndebug3: record_hostkey: found key type ECDSA in file /root/.ssh/known_hosts:3\r\ndebug3: load_hostkeys_file: loaded 2 keys from 85.192.20.98\r\ndebug1: load_hostkeys: fopen /root/.ssh/known_hosts2: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts2: No such file or directory\r\ndebug3: order_hostkeyalgs: have matching best-preference key type ssh-ed25519-cert-v01@openssh.com, using HostkeyAlgorithms verbatim\r\ndebug3: send packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT sent\r\ndebug3: receive packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT received\r\ndebug2: local client KEXINIT proposal\r\ndebug2: KEX algorithms: sntrup761x25519-sha512@openssh.com,curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group14-sha256,ext-info-c,kex-strict-c-v00@openssh.com\r\ndebug2: host key algorithms: ssh-ed25519-cert-v01@openssh.com,ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp384-cert-v01@openssh.com,ecdsa-sha2-nistp521-cert-v01@openssh.com,sk-ssh-ed25519-cert-v01@openssh.com,sk-ecdsa-sha2-nistp256-cert-v01@openssh.com,rsa-sha2-512-cert-v01@openssh.com,rsa-sha2-256-cert-v01@openssh.com,ssh-ed25519,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,sk-ssh-ed25519@openssh.com,sk-ecdsa-sha2-nistp256@openssh.com,rsa-sha2-512,rsa-sha2-256\r\ndebug2: ciphers ctos: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: ciphers stoc: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: MACs ctos: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: MACs stoc: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: compression ctos: zlib@openssh.com,zlib,none\r\ndebug2: compression stoc: zlib@openssh.com,zlib,none\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug2: peer server KEXINIT proposal\r\ndebug2: KEX algorithms: curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group14-sha256\r\ndebug2: host key algorithms: rsa-sha2-512,rsa-sha2-256,ssh-rsa,ecdsa-sha2-nistp256,ssh-ed25519\r\ndebug2: ciphers ctos: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: ciphers stoc: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: MACs ctos: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: MACs stoc: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: compression ctos: none,zlib@openssh.com\r\ndebug2: compression stoc: none,zlib@openssh.com\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug1: kex: algorithm: curve25519-sha256\r\ndebug1: kex: host key algorithm: ssh-ed25519\r\ndebug1: kex: server->client cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: zlib@openssh.com\r\ndebug1: kex: client->server cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: zlib@openssh.com\r\ndebug3: send packet: type 30\r\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\r\ndebug3: receive packet: type 31\r\ndebug1: SSH2_MSG_KEX_ECDH_REPLY received\r\ndebug1: Server host key: ssh-ed25519 SHA256:y3xIKwLhu6u767rHBCHDHLHvNWKoYb7c+YzsLpC4j2c\r\ndebug3: record_hostkey: found key type ED25519 in file /root/.ssh/known_hosts:1\r\ndebug3: record_hostkey: found key type ECDSA in file /root/.ssh/known_hosts:3\r\ndebug3: load_hostkeys_file: loaded 2 keys from 85.192.20.98\r\ndebug1: load_hostkeys: fopen /root/.ssh/known_hosts2: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts2: No such file or directory\r\ndebug1: Host \'85.192.20.98\' is known and matches the ED25519 host key.\r\ndebug1: Found key in /root/.ssh/known_hosts:1\r\ndebug3: send packet: type 21\r\ndebug2: ssh_set_newkeys: mode 1\r\ndebug1: rekey out after 134217728 blocks\r\ndebug1: SSH2_MSG_NEWKEYS sent\r\ndebug1: expecting SSH2_MSG_NEWKEYS\r\ndebug3: receive packet: type 21\r\ndebug1: SSH2_MSG_NEWKEYS received\r\ndebug2: ssh_set_newkeys: mode 0\r\ndebug1: rekey in after 134217728 blocks\r\ndebug1: Will attempt key: ./keys/id_rsa_old  explicit\r\ndebug2: pubkey_prepare: done\r\ndebug3: send packet: type 5\r\ndebug3: receive packet: type 7\r\ndebug1: SSH2_MSG_EXT_INFO received\r\ndebug1: kex_input_ext_info: server-sig-algs=<ssh-ed25519,sk-ssh-ed25519@openssh.com,ssh-rsa,rsa-sha2-256,rsa-sha2-512,ssh-dss,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,sk-ecdsa-sha2-nistp256@openssh.com,webauthn-sk-ecdsa-sha2-nistp256@openssh.com>\r\ndebug3: receive packet: type 6\r\ndebug2: service_accept: ssh-userauth\r\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\r\ndebug3: send packet: type 50\r\ndebug3: receive packet: type 51\r\ndebug1: Authentications that can continue: publickey\r\ndebug3: start over, passed a different list publickey\r\ndebug3: preferred gssapi-with-mic,gssapi-keyex,hostbased,publickey\r\ndebug3: authmethod_lookup publickey\r\ndebug3: remaining preferred: ,gssapi-keyex,hostbased,publickey\r\ndebug3: authmethod_is_enabled publickey\r\ndebug1: Next authentication method: publickey\r\ndebug1: Trying private key: ./keys/id_rsa_old\r\nno such identity: ./keys/id_rsa_old: No such file or directory\r\ndebug2: we did not send a packet, disable method\r\ndebug1: No more authentication methods to try.\r\nroot@85.192.20.98: Permission denied (publickey).\r\n')
fatal: [host43]: UNREACHABLE! => {
    "changed": false,
    "msg": "Failed to connect to the host via ssh: OpenSSH_9.2p1 Debian-2+deb12u2, OpenSSL 3.0.11 19 Sep 2023\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 19: include /etc/ssh/ssh_config.d/*.conf matched no files\r\ndebug1: /etc/ssh/ssh_config line 21: Applying options for *\r\ndebug2: resolve_canonicalize: hostname 85.192.20.98 is address\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts' -> '/root/.ssh/known_hosts'\r\ndebug3: expanded UserKnownHostsFile '~/.ssh/known_hosts2' -> '/root/.ssh/known_hosts2'\r\ndebug1: auto-mux: Trying existing master\r\ndebug1: Control socket \"/root/.ansible/cp/d17929321e\" does not exist\r\ndebug3: ssh_connect_direct: entering\r\ndebug1: Connecting to 85.192.20.98 [85.192.20.98] port 22.\r\ndebug3: set_sock_tos: set socket 3 IP_TOS 0x10\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: fd 3 clearing O_NONBLOCK\r\ndebug1: Connection established.\r\ndebug3: timeout: 10000 ms remain after connect\r\ndebug1: identity file ./keys/id_rsa_old type -1\r\ndebug1: identity file ./keys/id_rsa_old-cert type -1\r\ndebug1: Local version string SSH-2.0-OpenSSH_9.2p1 Debian-2+deb12u2\r\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_8.4p1 Debian-5+deb11u1\r\ndebug1: compat_banner: match: OpenSSH_8.4p1 Debian-5+deb11u1 pat OpenSSH* compat 0x04000000\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: Authenticating to 85.192.20.98:22 as 'root'\r\ndebug3: record_hostkey: found key type ED25519 in file /root/.ssh/known_hosts:1\r\ndebug3: record_hostkey: found key type ECDSA in file /root/.ssh/known_hosts:3\r\ndebug3: load_hostkeys_file: loaded 2 keys from 85.192.20.98\r\ndebug1: load_hostkeys: fopen /root/.ssh/known_hosts2: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts2: No such file or directory\r\ndebug3: order_hostkeyalgs: have matching best-preference key type ssh-ed25519-cert-v01@openssh.com, using HostkeyAlgorithms verbatim\r\ndebug3: send packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT sent\r\ndebug3: receive packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT received\r\ndebug2: local client KEXINIT proposal\r\ndebug2: KEX algorithms: sntrup761x25519-sha512@openssh.com,curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group14-sha256,ext-info-c,kex-strict-c-v00@openssh.com\r\ndebug2: host key algorithms: ssh-ed25519-cert-v01@openssh.com,ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp384-cert-v01@openssh.com,ecdsa-sha2-nistp521-cert-v01@openssh.com,sk-ssh-ed25519-cert-v01@openssh.com,sk-ecdsa-sha2-nistp256-cert-v01@openssh.com,rsa-sha2-512-cert-v01@openssh.com,rsa-sha2-256-cert-v01@openssh.com,ssh-ed25519,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,sk-ssh-ed25519@openssh.com,sk-ecdsa-sha2-nistp256@openssh.com,rsa-sha2-512,rsa-sha2-256\r\ndebug2: ciphers ctos: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: ciphers stoc: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: MACs ctos: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: MACs stoc: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: compression ctos: zlib@openssh.com,zlib,none\r\ndebug2: compression stoc: zlib@openssh.com,zlib,none\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug2: peer server KEXINIT proposal\r\ndebug2: KEX algorithms: curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group14-sha256\r\ndebug2: host key algorithms: rsa-sha2-512,rsa-sha2-256,ssh-rsa,ecdsa-sha2-nistp256,ssh-ed25519\r\ndebug2: ciphers ctos: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: ciphers stoc: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com\r\ndebug2: MACs ctos: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: MACs stoc: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: compression ctos: none,zlib@openssh.com\r\ndebug2: compression stoc: none,zlib@openssh.com\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug1: kex: algorithm: curve25519-sha256\r\ndebug1: kex: host key algorithm: ssh-ed25519\r\ndebug1: kex: server->client cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: zlib@openssh.com\r\ndebug1: kex: client->server cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: zlib@openssh.com\r\ndebug3: send packet: type 30\r\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\r\ndebug3: receive packet: type 31\r\ndebug1: SSH2_MSG_KEX_ECDH_REPLY received\r\ndebug1: Server host key: ssh-ed25519 SHA256:y3xIKwLhu6u767rHBCHDHLHvNWKoYb7c+YzsLpC4j2c\r\ndebug3: record_hostkey: found key type ED25519 in file /root/.ssh/known_hosts:1\r\ndebug3: record_hostkey: found key type ECDSA in file /root/.ssh/known_hosts:3\r\ndebug3: load_hostkeys_file: loaded 2 keys from 85.192.20.98\r\ndebug1: load_hostkeys: fopen /root/.ssh/known_hosts2: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts: No such file or directory\r\ndebug1: load_hostkeys: fopen /etc/ssh/ssh_known_hosts2: No such file or directory\r\ndebug1: Host '85.192.20.98' is known and matches the ED25519 host key.\r\ndebug1: Found key in /root/.ssh/known_hosts:1\r\ndebug3: send packet: type 21\r\ndebug2: ssh_set_newkeys: mode 1\r\ndebug1: rekey out after 134217728 blocks\r\ndebug1: SSH2_MSG_NEWKEYS sent\r\ndebug1: expecting SSH2_MSG_NEWKEYS\r\ndebug3: receive packet: type 21\r\ndebug1: SSH2_MSG_NEWKEYS received\r\ndebug2: ssh_set_newkeys: mode 0\r\ndebug1: rekey in after 134217728 blocks\r\ndebug1: Will attempt key: ./keys/id_rsa_old  explicit\r\ndebug2: pubkey_prepare: done\r\ndebug3: send packet: type 5\r\ndebug3: receive packet: type 7\r\ndebug1: SSH2_MSG_EXT_INFO received\r\ndebug1: kex_input_ext_info: server-sig-algs=<ssh-ed25519,sk-ssh-ed25519@openssh.com,ssh-rsa,rsa-sha2-256,rsa-sha2-512,ssh-dss,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,sk-ecdsa-sha2-nistp256@openssh.com,webauthn-sk-ecdsa-sha2-nistp256@openssh.com>\r\ndebug3: receive packet: type 6\r\ndebug2: service_accept: ssh-userauth\r\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\r\ndebug3: send packet: type 50\r\ndebug3: receive packet: type 51\r\ndebug1: Authentications that can continue: publickey\r\ndebug3: start over, passed a different list publickey\r\ndebug3: preferred gssapi-with-mic,gssapi-keyex,hostbased,publickey\r\ndebug3: authmethod_lookup publickey\r\ndebug3: remaining preferred: ,gssapi-keyex,hostbased,publickey\r\ndebug3: authmethod_is_enabled publickey\r\ndebug1: Next authentication method: publickey\r\ndebug1: Trying private key: ./keys/id_rsa_old\r\nno such identity: ./keys/id_rsa_old: No such file or directory\r\ndebug2: we did not send a packet, disable method\r\ndebug1: No more authentication methods to try.\r\nroot@85.192.20.98: Permission denied (publickey).",
    "unreachable": true
}

PLAY RECAP *********************************************************************
host43                     : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
fatal: [host43]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: no such identity: ./keys/id_rsa_old: No such file or directory\r\nroot@85.192.20.98: Permission denied (publickey).", "unreachable": true}

PLAY RECAP *********************************************************************
host43                     : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
fatal: [host43]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: no such identity: ./keys/id_rsa_old: No such file or directory\r\nroot@85.192.20.98: Permission denied (publickey).", "unreachable": true}

PLAY RECAP *********************************************************************
host43                     : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
fatal: [host43]: UNREACHABLE! => {"changed": false, "msg": "Failed to connect to the host via ssh: no such identity: /root/.config/sms./keys/id_rsa_old: No such file or directory\r\nroot@85.192.20.98: Permission denied (publickey).", "unreachable": true}

PLAY RECAP *********************************************************************
host43                     : ok=0    changed=0    unreachable=1    failed=0    skipped=0    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : mikrotik clean] ************************************************
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  found unacceptable key (unhashable type: 'AnsibleMapping')

The error appears to be in '/root/.config/sms/inventory/group_vars/mikrotik.yml': line 1, column 20, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


ansible_ssh_port: {{ CONFIG.MIKROTIK_SSH_PORT }}
                   ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : mikrotik clean] ************************************************

TASK [mikrotik_clean : node384 : clean old records] ****************************
changed: [mikrotik45]
changed: [mikrotik43]
changed: [mikrotik41]
changed: [mikrotik42]
fatal: [mikrotik44]: FAILED! => {"changed": false, "msg": "ssh connection failed: ssh connect failed: Timeout connecting to 217.67.189.234"}

PLAY [node384 : vpn reconfigure] ***********************************************

TASK [vpn_reconfigure : node384 : clean old records] ***************************
changed: [vpn226]

TASK [vpn_reconfigure : node384 : remove masquerade all] ***********************
ok: [vpn226]

TASK [vpn_reconfigure : node384 : add dstnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : add srcnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : netfilter-persistent save] *******************
changed: [vpn226]

PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=5    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik41                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik42                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik43                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik44                 : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
mikrotik45                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
vpn226                     : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : mikrotik clean] ************************************************

TASK [mikrotik_clean : node384 : clean old records] ****************************
changed: [mikrotik41]
changed: [mikrotik45]
changed: [mikrotik43]
changed: [mikrotik42]
fatal: [mikrotik44]: FAILED! => {"changed": false, "msg": "ssh connection failed: ssh connect failed: Timeout connecting to 217.67.189.234"}

PLAY [node384 : vpn reconfigure] ***********************************************

TASK [vpn_reconfigure : node384 : clean old records] ***************************
changed: [vpn226]

TASK [vpn_reconfigure : node384 : remove masquerade all] ***********************
ok: [vpn226]

TASK [vpn_reconfigure : node384 : add dstnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : add srcnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : netfilter-persistent save] *******************
changed: [vpn226]

PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=5    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik41                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik42                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik43                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik44                 : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
mikrotik45                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
vpn226                     : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : mikrotik clean] ************************************************

TASK [mikrotik_clean : node384 : clean old records] ****************************
changed: [mikrotik45]
changed: [mikrotik41]
changed: [mikrotik43]
changed: [mikrotik42]
fatal: [mikrotik44]: FAILED! => {"changed": false, "msg": "ssh connection failed: ssh connect failed: Timeout connecting to 217.67.189.234"}

PLAY [node384 : vpn reconfigure] ***********************************************

TASK [vpn_reconfigure : node384 : clean old records] ***************************
changed: [vpn226]

TASK [vpn_reconfigure : node384 : remove masquerade all] ***********************
ok: [vpn226]

TASK [vpn_reconfigure : node384 : add dstnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : add srcnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : netfilter-persistent save] *******************
changed: [vpn226]

PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=5    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik41                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik42                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik43                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik44                 : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
mikrotik45                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
vpn226                     : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : mikrotik clean] ************************************************

TASK [mikrotik_clean : node384 : clean old records] ****************************
changed: [mikrotik41]
changed: [mikrotik43]
changed: [mikrotik45]
changed: [mikrotik42]
fatal: [mikrotik44]: FAILED! => {"changed": false, "msg": "ssh connection failed: ssh connect failed: Timeout connecting to 217.67.189.234"}

PLAY [node384 : vpn reconfigure] ***********************************************

TASK [vpn_reconfigure : node384 : clean old records] ***************************
changed: [vpn226]

TASK [vpn_reconfigure : node384 : remove masquerade all] ***********************
ok: [vpn226]

TASK [vpn_reconfigure : node384 : add dstnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : add srcnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : netfilter-persistent save] *******************
changed: [vpn226]

PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=5    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik41                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik42                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik43                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik44                 : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
mikrotik45                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
vpn226                     : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
 [ERROR]: User interrupted execution

PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : mikrotik clean] ************************************************

TASK [mikrotik_clean : node384 : clean old records] ****************************
changed: [mikrotik45]
changed: [mikrotik41]
changed: [mikrotik43]
changed: [mikrotik42]
fatal: [mikrotik44]: FAILED! => {"changed": false, "msg": "ssh connection failed: ssh connect failed: Timeout connecting to 217.67.189.234"}

PLAY [node384 : vpn reconfigure] ***********************************************

TASK [vpn_reconfigure : node384 : clean old records] ***************************
changed: [vpn226]

TASK [vpn_reconfigure : node384 : remove masquerade all] ***********************
ok: [vpn226]

TASK [vpn_reconfigure : node384 : add dstnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : add srcnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : netfilter-persistent save] *******************
changed: [vpn226]

PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=5    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik41                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik42                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik43                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik44                 : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
mikrotik45                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
vpn226                     : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : mikrotik clean] ************************************************

TASK [mikrotik_clean : node384 : clean old records] ****************************
changed: [mikrotik42]
changed: [mikrotik43]
changed: [mikrotik41]
changed: [mikrotik45]
fatal: [mikrotik44]: FAILED! => {"changed": false, "msg": "ssh connection failed: ssh connect failed: Timeout connecting to 217.67.189.234"}

PLAY [node384 : vpn reconfigure] ***********************************************

TASK [vpn_reconfigure : node384 : clean old records] ***************************
changed: [vpn226]

TASK [vpn_reconfigure : node384 : remove masquerade all] ***********************
ok: [vpn226]

TASK [vpn_reconfigure : node384 : add dstnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : add srcnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : netfilter-persistent save] *******************
changed: [vpn226]

PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=5    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik41                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik42                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik43                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik44                 : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
mikrotik45                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
vpn226                     : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : mikrotik clean] ************************************************

TASK [mikrotik_clean : node384 : clean old records] ****************************
changed: [mikrotik45]
changed: [mikrotik42]
changed: [mikrotik41]
changed: [mikrotik43]
fatal: [mikrotik44]: FAILED! => {"changed": false, "msg": "ssh connection failed: ssh connect failed: Timeout connecting to 217.67.189.234"}

PLAY [node384 : vpn reconfigure] ***********************************************

TASK [vpn_reconfigure : node384 : clean old records] ***************************
changed: [vpn226]

TASK [vpn_reconfigure : node384 : remove masquerade all] ***********************
ok: [vpn226]

TASK [vpn_reconfigure : node384 : add dstnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : add srcnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : netfilter-persistent save] *******************
changed: [vpn226]

PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=5    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik41                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik42                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik43                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik44                 : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
mikrotik45                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
vpn226                     : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : vpn reconfigure] ***********************************************

TASK [vpn_reconfigure : node384 : clean old records] ***************************
changed: [vpn226]

TASK [vpn_reconfigure : node384 : remove masquerade all] ***********************
ok: [vpn226]

TASK [vpn_reconfigure : node384 : add dstnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : add srcnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : netfilter-persistent save] *******************
changed: [vpn226]

PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=5    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
vpn226                     : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  did not find expected '-' indicator

The error appears to be in '/root/storj_management_shell_dev/playbooks/node_create_full.yml': line 54, column 2, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

- name: "node{{ NODE_ID }} : mikrotik create dstnat"
 hosts: current_mikrotik
 ^ here

PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : mikrotik create dstnat] ****************************************

TASK [mikrotik_create_dstnat : node384 : create mikrotik43 dst-nat] ************
changed: [mikrotik43]

PLAY [node384 : vpn reconfigure] ***********************************************

TASK [vpn_reconfigure : node384 : clean old records] ***************************
changed: [vpn226]

TASK [vpn_reconfigure : node384 : remove masquerade all] ***********************
ok: [vpn226]

TASK [vpn_reconfigure : node384 : add dstnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : add srcnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : netfilter-persistent save] *******************
changed: [vpn226]

PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=5    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
mikrotik43                 : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
vpn226                     : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node : select hosts] *****************************************************

TASK [debug] *******************************************************************
fatal: [localhost]: FAILED! => {"msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', nodeconfig_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '/root/.config/sms/configuration_items/node//config'. file not found, use -vvvvv to see paths searched"}

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node : select hosts] *****************************************************

TASK [debug] *******************************************************************
fatal: [localhost]: FAILED! => {"msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', nodeconfig_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '/root/.config/sms/configuration_items/node//config'. file not found, use -vvvvv to see paths searched"}

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node : select hosts] *****************************************************

TASK [debug] *******************************************************************
fatal: [localhost]: FAILED! => {"msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', nodeconfig_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '/root/.config/sms/configuration_items/node//config'. file not found, use -vvvvv to see paths searched"}

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=5    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

TASK [add_host] ****************************************************************
changed: [localhost]

PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=5    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
localhost                  : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

Traceback (most recent call last):
  File "/root/venv/bin/ansible-playbook", line 5, in <module>
    from ansible.cli.playbook import main
  File "/root/venv/lib/python3.11/site-packages/ansible/cli/playbook.py", line 20, in <module>
    from ansible.executor.playbook_executor import PlaybookExecutor
  File "/root/venv/lib/python3.11/site-packages/ansible/executor/playbook_executor.py", line 26, in <module>
    from ansible.executor.task_queue_manager import TaskQueueManager, AnsibleEndPlay
  File "/root/venv/lib/python3.11/site-packages/ansible/executor/task_queue_manager.py", line 33, in <module>
    from ansible.executor.play_iterator import PlayIterator
  File "/root/venv/lib/python3.11/site-packages/ansible/executor/play_iterator.py", line 29, in <module>
    from ansible.playbook.block import Block
  File "/root/venv/lib/python3.11/site-packages/ansible/playbook/__init__.py", line 27, in <module>
    from ansible.playbook.play import Play
  File "/root/venv/lib/python3.11/site-packages/ansible/playbook/play.py", line 30, in <module>
    from ansible.playbook.block import Block
  File "/root/venv/lib/python3.11/site-packages/ansible/playbook/block.py", line 28, in <module>
    from ansible.playbook.delegatable import Delegatable
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1032, in get_code
  File "<frozen importlib._bootstrap_external>", line 1131, in get_data
KeyboardInterrupt

PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

ERROR! The field 'hosts' has an invalid value, which includes an undefined variable. The error was: 'str object' has no attribute 'NODE_HOST_ID'. 'str object' has no attribute 'NODE_HOST_ID'

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 1, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: "node{{ CONFIG.NODE_ID }} : create node docker container from scratch"
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ERROR! The field 'hosts' has an invalid value, which includes an undefined variable. The error was: 'CONFIG' is undefined. 'CONFIG' is undefined

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 1, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: "node{{ CONFIG.NODE_ID }} : create node docker container from scratch"
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ERROR! The field 'hosts' has an invalid value, which includes an undefined variable. The error was: 'CONFIG' is undefined. 'CONFIG' is undefined

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 1, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: "node{{ CONFIG.NODE_ID }} : create node docker container from scratch"
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ERROR! The field 'hosts' has an invalid value, which includes an undefined variable. The error was: 'CONFIG' is undefined. 'CONFIG' is undefined

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 1, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: "node{{ NODE_ID }} : create node docker container from scratch"
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ERROR! The field 'hosts' has an invalid value, which includes an undefined variable. The error was: 'CONFIG' is undefined. 'CONFIG' is undefined

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 1, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: "node{{ NODE_ID }} : create node docker container from scratch"
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

PLAY [node : create node docker container from scratch] ************************

TASK [node{{ CONFIG.NODE_ID }} : get dataset mount point] **********************
fatal: [localhost]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ lookup('file', defaults_filename) | from_json }}: {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. {{ CONFIG_PATH }}/defaults: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 5, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  pre_tasks:\n    - name: \"node{{ CONFIG.NODE_ID }} : get dataset mount point\"\n      ^ here\nWe could be wrong, but this one looks like it might be an issue with\nmissing quotes. Always quote template expression brackets when they\nstart a value. For instance:\n\n    with_items:\n      - {{ foo }}\n\nShould be written as:\n\n    with_items:\n      - \"{{ foo }}\"\n"}

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[WARNING]: Could not match supplied host pattern, ignoring: current_host

PLAY [node384 : create node docker container from scratch] *********************
skipping: no hosts matched

PLAY RECAP *********************************************************************

[WARNING]: Could not match supplied host pattern, ignoring: current_host

PLAY [node384 : create node docker container from scratch] *********************
skipping: no hosts matched

PLAY RECAP *********************************************************************

ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  found unacceptable key (unhashable type: 'AnsibleMapping')

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 2, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

- name: "node{{ NODE_ID }} : create node docker container from scratch"
  hosts: {{ CONFIG.HOST_IP_ADDRESS }}
          ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ERROR! The field 'hosts' has an invalid value, which includes an undefined variable. The error was: 'CONFIG' is undefined. 'CONFIG' is undefined

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 1, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: "node{{ NODE_ID }} : create node docker container from scratch"
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  found unacceptable key (unhashable type: 'AnsibleMapping')

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 2, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

- name: "node{{ NODE_ID }} : create node docker container from scratch"
  hosts: {{ CONFIG.HOST_IP_ADDRESS }}
          ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[WARNING]:  * Failed to parse /root/.config/sms/inventory/static-inventory with
yaml plugin: Unable to retrieve file contents Could not find or access
'/tmp/c02ade24-be73-464d-9d5b-daaf66fe95b3.json NODE_ID=384
CONFIG_PATH=/root/.config/sms' on the Ansible Controller. If you are using a
module and expect the file to exist on the remote, see the remote_src option
[WARNING]:  * Failed to parse /root/.config/sms/inventory/static-inventory with
ini plugin: Unable to retrieve file contents Could not find or access
'/tmp/c02ade24-be73-464d-9d5b-daaf66fe95b3.json NODE_ID=384
CONFIG_PATH=/root/.config/sms' on the Ansible Controller. If you are using a
module and expect the file to exist on the remote, see the remote_src option
[WARNING]: Unable to parse /root/.config/sms/inventory/static-inventory as an
inventory source
[WARNING]: Unable to parse /root/.config/sms/inventory as an inventory source
[WARNING]: No inventory was parsed, only implicit localhost is available
ERROR! Unable to retrieve file contents
Could not find or access '/tmp/c02ade24-be73-464d-9d5b-daaf66fe95b3.json NODE_ID=384 CONFIG_PATH=/root/.config/sms' on the Ansible Controller.
If you are using a module and expect the file to exist on the remote, see the remote_src option

PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  found unacceptable key (unhashable type: 'AnsibleMapping')

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 2, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

- name: "node{{ NODE_ID }} : create node docker container from scratch"
  hosts: {{ CONFIG.HOST_IP_ADDRESS }}
          ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  found unacceptable key (unhashable type: 'AnsibleMapping')

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 2, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

- name: "node{{ NODE_ID }} : create node docker container from scratch"
  hosts: {{ HOST_IP_ADDRESS }}
          ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[WARNING]: Could not match supplied host pattern, ignoring: 85.192.20.98

PLAY [node384 : create node docker container from scratch] *********************
skipping: no hosts matched

PLAY RECAP *********************************************************************


PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : create node docker container from scratch] *********************

TASK [node{{ CONFIG.NODE_ID }} : get dataset mount point] **********************
fatal: [host43]: FAILED! => {"msg": "The field 'private_key_file' has an invalid value, which includes an undefined variable. The error was: 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined. 'CONFIG_PATH' is undefined"}

PLAY RECAP *********************************************************************
host43                     : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : create node docker container from scratch] *********************

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [node384 : set mountpoint variable] ***************************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

ERROR! The field 'hosts' has an invalid value, which includes an undefined variable. The error was: 'NODE_HOST_ID' is undefined. 'NODE_HOST_ID' is undefined

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 1, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: "node{{ CONFIG.NODE_ID }} : create node docker container from scratch"
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"
Traceback (most recent call last):
  File "/root/venv/bin/ansible-playbook", line 5, in <module>
    from ansible.cli.playbook import main
  File "/root/venv/lib/python3.11/site-packages/ansible/cli/__init__.py", line 88, in <module>
    from ansible import constants as C
  File "/root/venv/lib/python3.11/site-packages/ansible/constants.py", line 182, in <module>
    config = ConfigManager()
             ^^^^^^^^^^^^^^^
  File "/root/venv/lib/python3.11/site-packages/ansible/config/manager.py", line 293, in __init__
    self._base_defs = self._read_config_yaml_file(defs_file or ('%s/base.yml' % os.path.dirname(__file__)))
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/lib/python3.11/site-packages/ansible/config/manager.py", line 314, in _read_config_yaml_file
    return yaml_load(config_def) or {}
           ^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/lib/python3.11/site-packages/yaml/__init__.py", line 81, in load
    return loader.get_single_data()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/venv/lib/python3.11/site-packages/yaml/constructor.py", line 49, in get_single_data
    node = self.get_single_node()
           ^^^^^^^^^^^^^^^^^^^^^^
  File "yaml/_yaml.pyx", line 673, in yaml._yaml.CParser.get_single_node
  File "yaml/_yaml.pyx", line 687, in yaml._yaml.CParser._compose_document
  File "yaml/_yaml.pyx", line 731, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 845, in yaml._yaml.CParser._compose_mapping_node
  File "yaml/_yaml.pyx", line 731, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 845, in yaml._yaml.CParser._compose_mapping_node
  File "yaml/_yaml.pyx", line 729, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 806, in yaml._yaml.CParser._compose_sequence_node
  File "yaml/_yaml.pyx", line 731, in yaml._yaml.CParser._compose_node
  File "yaml/_yaml.pyx", line 829, in yaml._yaml.CParser._compose_mapping_node
  File "/root/venv/lib/python3.11/site-packages/yaml/resolver.py", line 143, in resolve
    def resolve(self, kind, value, implicit):

KeyboardInterrupt

PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

ERROR! The field 'hosts' has an invalid value, which includes an undefined variable. The error was: 'NODE_HOST_ID' is undefined. 'NODE_HOST_ID' is undefined

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 1, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: "node{{ CONFIG.NODE_ID }} : create node docker container from scratch"
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
fatal: [localhost]: FAILED! => {"msg": "template error while templating string: expected token 'end of print statement', got ':'. String: {{ { 'current_host': 'host' + CONFIG.NODE_HOST_ID, 'current_mikrotik': 'mikrotik' + CONFIG.NODE_MIKROTIK_ID }, 'current_node': 'node' + CONFIG.NODE_ID }}. expected token 'end of print statement', got ':'"}

PLAY RECAP *********************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
fatal: [localhost]: FAILED! => {"msg": "template error while templating string: expected token 'end of print statement', got ':'. String: {{ { 'current_host': 'host' + CONFIG.NODE_HOST_ID, 'current_mikrotik': 'mikrotik' + CONFIG.NODE_MIKROTIK_ID }, 'current_node': 'node' + CONFIG.NODE_ID } }}. expected token 'end of print statement', got ':'"}

PLAY RECAP *********************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate node config] ******************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

ERROR! The field 'hosts' has an invalid value, which includes an undefined variable. The error was: 'NODE_HOST_ID' is undefined. 'NODE_HOST_ID' is undefined

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 1, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: "node{{ CONFIG.NODE_ID }} : create node docker container from scratch"
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[WARNING]: Could not match supplied host pattern, ignoring: current_host

PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****
skipping: no hosts matched

PLAY RECAP *********************************************************************


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

ERROR! We were unable to read either as JSON nor YAML, these are the errors we got from each:
JSON: Expecting value: line 1 column 1 (char 0)

Syntax Error while loading YAML.
  found unacceptable key (unhashable type: 'AnsibleMapping')

The error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 2, column 11, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

- name: "node{{ CONFIG.NODE_ID }} : create node docker container from scratch"
  hosts: {{ current_host }}
          ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node{{ CONFIG.NODE_ID }} : get dataset mount point] **********************
fatal: [host43]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 5, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  pre_tasks:\n    - name: \"node{{ CONFIG.NODE_ID }} : get dataset mount point\"\n      ^ here\nWe could be wrong, but this one looks like it might be an issue with\nmissing quotes. Always quote template expression brackets when they\nstart a value. For instance:\n\n    with_items:\n      - {{ foo }}\n\nShould be written as:\n\n    with_items:\n      - \"{{ foo }}\"\n"}

PLAY RECAP *********************************************************************
host43                     : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [debug] *******************************************************************
fatal: [host43]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}: {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}: {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ lookup('file', nodeconfig_filename) | from_json }}: {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined. {{ CONFIG_PATH }}/configuration_items/node/{{ NODE_ID }}/config: 'NODE_ID' is undefined. 'NODE_ID' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/create_node_docker_container_from_scratch.yml': line 5, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  pre_tasks:\n    - debug:\n      ^ here\n"}

PLAY RECAP *********************************************************************
host43                     : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [debug] *******************************************************************
ok: [host43] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [debug] *******************************************************************
ok: [host43] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=13   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
 [ERROR]: User interrupted execution
[WARNING]:  * Failed to parse /root/.config/sms/inventory/static-inventory with
yaml plugin: Unable to retrieve file contents Could not find or access
'/tmp/dd0c2367-10fd-434e-b2d7-3145d181b231.json' on the Ansible Controller. If
you are using a module and expect the file to exist on the remote, see the
remote_src option
[WARNING]:  * Failed to parse /root/.config/sms/inventory/static-inventory with
ini plugin: Unable to retrieve file contents Could not find or access
'/tmp/dd0c2367-10fd-434e-b2d7-3145d181b231.json' on the Ansible Controller. If
you are using a module and expect the file to exist on the remote, see the
remote_src option
[WARNING]: Unable to parse /root/.config/sms/inventory/static-inventory as an
inventory source
[WARNING]: Unable to parse /root/.config/sms/inventory as an inventory source
[WARNING]: No inventory was parsed, only implicit localhost is available
ERROR! Unable to retrieve file contents
Could not find or access '/tmp/dd0c2367-10fd-434e-b2d7-3145d181b231.json' on the Ansible Controller.
If you are using a module and expect the file to exist on the remote, see the remote_src option

PLAY [node : generate session config (select hosts)] ***************************

TASK [debug] *******************************************************************
fatal: [localhost]: FAILED! => {"msg": "An unhandled exception occurred while templating '{{ TEMPCONFIG01 | combine(NODE_IP_ADDRESS_CONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ DEFAULTS | combine (NODECONFIG) | combine ({'NODE_ID':NODE_ID}) |  combine(VPNCONFIG) | combine(HOSTCONFIG) | combine(MIKROTIKCONFIG) }}'. Error was a <class 'ansible.errors.AnsibleError'>, original message: An unhandled exception occurred while templating '{{ lookup('file', nodeconfig_filename) | from_json }}'. Error was a <class 'ansible.errors.AnsibleLookupError'>, original message: The 'file' lookup had an issue accessing the file '/root/.config/sms/configuration_items/node//config'. file not found, use -vvvvv to see paths searched"}

PLAY RECAP *********************************************************************
localhost                  : ok=0    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : select hosts] **************************************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
fatal: [localhost]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'UUID' is undefined. 'UUID' is undefined\n\nThe error appears to be in '/root/storj_management_shell_dev/playbooks/node_create_full.yml': line 9, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n        msg: \"{{ CONFIG }}\"\n    - copy:\n      ^ here\n"}

PLAY RECAP *********************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   

ERROR! The field 'hosts' has an invalid value, which includes an undefined variable. The error was: 'current_vpn' is undefined. 'current_vpn' is undefined

The error appears to be in '/root/storj_management_shell_dev/playbooks/reconfigure_node_vpn.yml': line 1, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


- name: "node{{ NODE_ID }} : reconfigure node vpn"
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
fatal: [localhost]: FAILED! => {"msg": "Unexpected templating type error occurred on ({{ { 'current_host': 'host' + CONFIG.NODE_HOST_ID, 'current_mikrotik': 'mikrotik' + CONFIG.NODE_MIKROTIK_ID, 'current_vpn': 'vpn' + CONFIG.NODE_VPN_ID, 'current_node': 'node' + CONFIG.NODE_ID, 'NODE_ID': CONFIG.NODE_ID, 'CONFIG_PATH': CONFIG_PATH } }}): can only concatenate str (not \"int\") to str. can only concatenate str (not \"int\") to str"}

PLAY RECAP *********************************************************************
localhost                  : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : reconfigure node vpn] ******************************************

TASK [vpn_reconfigure : node384 : clean old records] ***************************
changed: [vpn226]

TASK [vpn_reconfigure : node384 : remove masquerade all] ***********************
ok: [vpn226]

TASK [vpn_reconfigure : node384 : add dstnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : add srcnat rules] ****************************
changed: [vpn226] => (item=udp)
 [ERROR]: User interrupted execution

PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
changed: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=4    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : reconfigure node vpn] ******************************************

TASK [vpn_reconfigure : node384 : clean old records] ***************************
changed: [vpn226]

TASK [vpn_reconfigure : node384 : remove masquerade all] ***********************
ok: [vpn226]

TASK [vpn_reconfigure : node384 : add dstnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : add srcnat rules] ****************************
changed: [vpn226] => (item=udp)
changed: [vpn226] => (item=tcp)

TASK [vpn_reconfigure : node384 : netfilter-persistent save] *******************
changed: [vpn226]

PLAY RECAP *********************************************************************
vpn226                     : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node351 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://iphoster.net",
        "HOST_IP_ADDRESS": "10.45.0.254",
        "HOST_PROCESSING": 0,
        "MIKROTIK_IP_ADDRESS": "217.67.189.234",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.44.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "45",
        "NODE_ID": "351",
        "NODE_IP_ADDRESS_EXTERNAL": "51.83.170.96",
        "NODE_IP_ADDRESS_INTERNAL": "10.45.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "44",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "my",
        "NODE_PORT_CONSOLE": "11351",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10351",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 1000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": "126",
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "51.83.170.96",
        "VPN_IP_ADDRESS_LIST": [
            "51.83.170.96"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node331 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://iphoster.net/",
        "HOST_IP_ADDRESS": "10.45.0.254",
        "HOST_PROCESSING": 0,
        "MIKROTIK_IP_ADDRESS": "217.67.189.234",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.44.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "45",
        "NODE_ID": "331",
        "NODE_IP_ADDRESS_EXTERNAL": "51.89.124.128",
        "NODE_IP_ADDRESS_INTERNAL": "10.45.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "44",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "my",
        "NODE_PORT_CONSOLE": "11331",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10331",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 1000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": "212",
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "51.89.124.128",
        "VPN_IP_ADDRESS_LIST": [
            "51.89.124.128"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node336 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "10.45.0.254",
        "HOST_PROCESSING": 0,
        "MIKROTIK_IP_ADDRESS": "217.67.189.234",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.44.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "45",
        "NODE_ID": "336",
        "NODE_IP_ADDRESS_EXTERNAL": "5.78.24.149",
        "NODE_IP_ADDRESS_INTERNAL": "10.45.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "44",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11336",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10336",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": "226",
        "NODE_VPN_IP_ADDRESS_NUMBER": 1,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node187 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "187",
        "NODE_IP_ADDRESS_EXTERNAL": "5.78.16.0",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "node187",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poolf",
        "NODE_PORT_CONSOLE": "11187",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10187",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 15000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 4,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node206 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://iphoster.net/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "206",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.92.36",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "node206_mailru",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11206",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10206",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 11400,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": "213",
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "51.83.170.111",
        "VPN_IP_ADDRESS_LIST": [
            "51.83.170.111"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : start node docker container] ***********************************

TASK [docker_stop_node_container : node101 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node101 : stop docker container] ************
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
ok: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : start node docker container] ***********************************

TASK [docker_start_node_container : node101 : start docker container] **********
 [ERROR]: User interrupted execution

PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : start node docker container] ***********************************

TASK [docker_stop_node_container : node101 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node101 : stop docker container] ************
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : start node docker container] ***********************************

TASK [docker_stop_node_container : node101 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node101 : stop docker container] ************
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node146 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://iphoster.net/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "146",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.86.50",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "node146",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11146",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10146",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": "211",
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "51.77.62.102",
        "VPN_IP_ADDRESS_LIST": [
            "51.77.62.102"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node146 : start node docker container] ***********************************

TASK [docker_stop_node_container : node146 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node146 : stop docker container] ************
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node206 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://iphoster.net/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "206",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.92.36",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "node206_mailru",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11206",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10206",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 11400,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": "213",
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "51.83.170.111",
        "VPN_IP_ADDRESS_LIST": [
            "51.83.170.111"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node206 : start node docker container] ***********************************

TASK [docker_stop_node_container : node206 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node206 : stop docker container] ************
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_stop_node_container : node384 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node384 : stop docker container] ************
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node206 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://iphoster.net/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "206",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.92.36",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "node206_mailru",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11206",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10206",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 11400,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": "213",
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "51.83.170.111",
        "VPN_IP_ADDRESS_LIST": [
            "51.83.170.111"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": "9500",
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : start node docker container] ***********************************

TASK [docker_stop_node_container : node101 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node101 : stop docker container] ************
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": "9500",
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": "9500",
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : start node docker container] ***********************************

TASK [docker_stop_node_container : node101 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node101 : stop docker container] ************
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : start node docker container] ***********************************

TASK [docker_start_node_container : node101 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": "9500",
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : start node docker container] ***********************************

TASK [docker_stop_node_container : node101 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node101 : stop docker container] ************
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : start node docker container] ***********************************

TASK [docker_start_node_container : node101 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "101",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.90.131",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11101",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10101",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": "9500",
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 44,
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_COMMENT": "https://iphoster.net/",
        "VPN_IP_ADDRESS": "178.33.69.92",
        "VPN_IP_ADDRESS_LIST": [
            "178.33.69.92"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node101 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node101 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node101 : stop docker container] **************
ok: [host43]

TASK [docker_rm_node_container : node101 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node101 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node101 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node101 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node101 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node101 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node101 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node101 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node101 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node101 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=3    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node101 : reconfigure node vpn] ******************************************

TASK [vpn_reconfigure : node101 : clean old records] ***************************
changed: [vpn44]

TASK [vpn_reconfigure : node101 : remove masquerade all] ***********************
ok: [vpn44]

TASK [vpn_reconfigure : node101 : add dstnat rules] ****************************
changed: [vpn44] => (item=udp)
changed: [vpn44] => (item=tcp)

TASK [vpn_reconfigure : node101 : add srcnat rules] ****************************
changed: [vpn44] => (item=udp)
changed: [vpn44] => (item=tcp)

TASK [vpn_reconfigure : node101 : netfilter-persistent save] *******************
changed: [vpn44]

PLAY RECAP *********************************************************************
vpn44                      : ok=5    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node101 : start node docker container] ***********************************

TASK [docker_start_node_container : node101 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node146 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://iphoster.net/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "146",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.86.50",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "node146",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11146",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10146",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 9800,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": "211",
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "51.77.62.102",
        "VPN_IP_ADDRESS_LIST": [
            "51.77.62.102"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node146 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node146 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node146 : stop docker container] **************
ok: [host43]

TASK [docker_rm_node_container : node146 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node146 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node146 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node146 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node146 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node146 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node146 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node146 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node146 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node146 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=3    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node146 : start node docker container] ***********************************

TASK [docker_start_node_container : node146 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node206 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://iphoster.net/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "206",
        "NODE_IP_ADDRESS_EXTERNAL": "217.25.92.36",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "node206_mailru",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11206",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": "10206",
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 11400,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": "213",
        "NODE_VPN_IP_ADDRESS_NUMBER": 0,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "51.83.170.111",
        "VPN_IP_ADDRESS_LIST": [
            "51.83.170.111"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node206 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node206 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node206 : stop docker container] **************
ok: [host43]

TASK [docker_rm_node_container : node206 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node206 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node206 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node206 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node206 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node206 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node206 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node206 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node206 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node206 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=3    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node206 : start node docker container] ***********************************

TASK [docker_start_node_container : node206 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
ok: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=3    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_stop_node_container : node384 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node384 : stop docker container] ************
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : get container's info] ************
ok: [host43]

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : get container's info] ************
ok: [host43]

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
ok: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=3    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
ok: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=3    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_stop_node_container : node384 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node384 : stop docker container] ************
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node{{ CONFIG.NODE_ID }} : create node docker container from scratch] ****

TASK [node384 : get dataset mount point] ***************************************
changed: [host43]

TASK [current_node : set mountpoint variable] **********************************
ok: [host43]

TASK [node384 : get container's info] ******************************************
ok: [host43]

TASK [docker_rm_node_container : node384 : stop docker container] **************
ok: [host43]

TASK [docker_rm_node_container : node384 : remove docker container] ************
changed: [host43]

TASK [docker_create_node_container : node384 : check identity exists] **********
ok: [host43]

TASK [docker_create_node_container : node384 : copy Identity] ******************
skipping: [host43]

TASK [docker_create_node_container : node384 : check config exists] ************
ok: [host43]

TASK [docker_create_node_container : node384 : create docker container (first time run)] ***
skipping: [host43]

TASK [docker_create_node_container : node384 : create docker container] ********
changed: [host43]

TASK [node_config_max-concurrent-requests : node384 : set storage2.max-concurrent-requests 130] ***
ok: [host43]

TASK [node_config_log_level : node384 : set log level to info to config file] ***
ok: [host43]

TASK [node_config_piece_scan_on_startup : node384 : set storage2.piece-scan-on-startup false to config file] ***
ok: [host43]

TASK [node_config_zksync : node384 : set operator.wallet-features zksync to config file] ***
ok: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=12   changed=3    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=1    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_stop_node_container : node384 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node384 : stop docker container] ************
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : get container's info] ************
ok: [host43]

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": 2000,
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
ok: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : generate session config (select hosts)] ************************

TASK [debug] *******************************************************************
ok: [localhost] => {
    "msg": {
        "COMMENT": "https://console.hetzner.cloud/",
        "HOST_IP_ADDRESS": "85.192.20.98",
        "HOST_PROCESSING": 1,
        "MIKROTIK_IP_ADDRESS": "85.192.20.99",
        "MIKROTIK_IP_ADDRESS_INTERNAL": "10.43.0.1",
        "MIKROTIK_SSH_PORT": 2222,
        "NODE_EMAIL": "syncamide@gmail.com",
        "NODE_ENABLE_LAZY_FILEWALKER": "true",
        "NODE_HOST_ID": "43",
        "NODE_ID": "384",
        "NODE_IP_ADDRESS_EXTERNAL": "188.225.11.204",
        "NODE_IP_ADDRESS_INTERNAL": "10.43.0.254",
        "NODE_LOG_LEVEL": "info",
        "NODE_MAX_CONCURRENT_REQUESTS": "130",
        "NODE_MIKROTIK_ID": "43",
        "NODE_NAME": "",
        "NODE_PIECE_SCAN_ON_STARTUP": "false",
        "NODE_POOL_NAME": "poola",
        "NODE_PORT_CONSOLE": "11384",
        "NODE_PORT_CONSOLE_PREFIX": "11",
        "NODE_PORT_EXTERNAL": 10299,
        "NODE_PORT_EXTERNAL_PREFIX": "10",
        "NODE_PORT_EXTERNAL_TYPE": "plain",
        "NODE_STORAGE": "1900",
        "NODE_STORAGENODE_PORT": 28967,
        "NODE_VPN_ID": 226,
        "NODE_VPN_IP_ADDRESS_NUMBER": 3,
        "NODE_VPN_TYPE": "dstnat",
        "NODE_WALLET": "0xfb2c6f2b49De68C45aF258744991D4802AE752eB",
        "SYSLOG_SERVER": "syslog-storj.meckil.ru",
        "VPN_IP_ADDRESS": "5.78.98.25",
        "VPN_IP_ADDRESS_LIST": [
            "5.78.98.25",
            "5.78.24.149",
            "5.78.31.149",
            "5.78.30.103",
            "5.78.16.0"
        ],
        "VPN_SSH_PORT": "22"
    }
}

TASK [copy] ********************************************************************
changed: [localhost]

TASK [copy] ********************************************************************
changed: [localhost]

PLAY RECAP *********************************************************************
localhost                  : ok=3    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_stop_node_container : node384 : get container's info] *************
ok: [host43]

TASK [docker_stop_node_container : node384 : stop docker container] ************
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   


PLAY [node384 : start node docker container] ***********************************

TASK [docker_start_node_container : node384 : get container's info] ************
ok: [host43]

TASK [docker_start_node_container : node384 : start docker container] **********
changed: [host43]

PLAY RECAP *********************************************************************
host43                     : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

